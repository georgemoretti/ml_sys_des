{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63210e5f",
   "metadata": {},
   "source": [
    "# Часть 1: Формулировка ML-задачи и выбор модели\n",
    "\n",
    "## 1. Бизнес-цели и метрики\n",
    "\n",
    "Прежде чем углубляться в ML, зафиксируем бизнес-контекст. Основная цель — повысить доверие пользователей к платформе (Trust & Safety) и оптимизировать операционные расходы.\n",
    "\n",
    "**Ключевые бизнес-метрики:**\n",
    "\n",
    "1.  **Reduction in Moderation Cost (Снижение затрат на модерацию):**\n",
    "    * *Цель:* Автоматизировать 90%+ решений. Уменьшить количество отзывов, требующих ручной проверки модераторами-людьми.\n",
    "2.  **Conversion Rate Impact (Влияние на конверсию):**\n",
    "    * *Цель:* Увеличение конверсии в покупку на страницах товаров. (Гипотеза: пользователи, доверяющие отзывам, покупают чаще; наличие очевидного спама снижает конверсию).\n",
    "3.  **User Retention (Удержание пользователей):**\n",
    "    * *Цель:* Снижение оттока (Churn Rate) среди пользователей, которые пишут отзывы (честные авторы уходят, если видят, что платформу наводнили боты).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Определение ML-задачи\n",
    "\n",
    "### Формулировка задачи\n",
    "Задача формулируется как **бинарная классификация (Binary Classification)**.\n",
    "Для каждого поступающего отзыва $x$ модель должна предсказать вероятность того, что он является фейковым: $P(y=1 | x)$, где $y=1$ — фейк/спам, $y=0$ — реальный отзыв.\n",
    "\n",
    "*Примечание:* Также возможен подход *Anomaly Detection* (поиск аномалий), но в условиях наличия размеченных данных (от модераторов) классификация даст более точный и интерпретируемый результат.\n",
    "\n",
    "### Таргет (Целевая переменная)\n",
    "Целевая переменная $y$ бинарна:\n",
    "* **1 (Positive):** Фейковый отзыв (накрутка рейтинга, спам, отзыв конкурента, сгенерированный текст без покупки).\n",
    "* **0 (Negative):** Подлинный отзыв реального пользователя.\n",
    "\n",
    "**Источник разметки (Ground Truth):**\n",
    "* Исторические логи ручной модерации.\n",
    "* Жалобы пользователей (\"Report this review\").\n",
    "* Эвристики (например, отзывы с IP-адресов известных бот-ферм).\n",
    "\n",
    "### Необходимые данные (Feature Engineering)\n",
    "Учитывая требование анализировать текст, поведение и графы, нам понадобятся три группы признаков:\n",
    "\n",
    "1.  **Текстовые признаки (Text Features):**\n",
    "    * Raw Text: Сам текст отзыва.\n",
    "    * NLP-метаданные: Длина текста, наличие капса, обилие эмодзи, sentiment score (слишком восторженные или агрессивные), повторяющиеся n-граммы (copy-paste).\n",
    "    * Embeddings: Векторные представления текста (из BERT/RoBERTa) для улавливания семантики \"рекламного\" языка.\n",
    "\n",
    "2.  **Поведенческие признаки пользователя (User Behavior):**\n",
    "    * User Tenure: Возраст аккаунта.\n",
    "    * Velocity: Количество отзывов, оставленных за последний час/день (RPS пользователя).\n",
    "    * Review Distribution: Средняя оценка пользователя (если у пользователя 100% отзывов — это 5 звезд, это подозрительно).\n",
    "    * Verified Purchase: Был ли куплен товар через платформу.\n",
    "    * Device/IP Fingerprints: Смена User-Agent, использование VPN/Proxy.\n",
    "\n",
    "3.  **Графовые признаки (Graph Features):**\n",
    "    * Связи User-Item-IP.\n",
    "    * *Co-review graph:* Признаки, указывающие на сговор (группа пользователей $A, B, C$ всегда комментирует одни и те же товары $X, Y, Z$ в одно и то же время).\n",
    "    * Компоненты связности: Размер кластера, к которому принадлежит пользователь.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Выбор модели\n",
    "\n",
    "Учитывая высокую нагрузку (**16,370 RPS**) и жесткий SLA (**435 ms**), выбор модели — это компромисс между точностью и скоростью.\n",
    "\n",
    "### Вариант 1: Гибридная нейросеть (Fine-tuned DistilBERT + Dense Layers)\n",
    "Архитектура, где текстовая часть обрабатывается легковесным трансформером, а выходной вектор конкатенируется с метаданными (поведение + граф) и подается в полносвязные слои.\n",
    "\n",
    "* **Преимущества:**\n",
    "    * SOTA (State-of-the-Art) качество анализа текста. Отлично ловит смысловые паттерны фейков (например, GPT-generated отзывы).\n",
    "    * End-to-end обучение (текст и фичи обучаются вместе).\n",
    "* **Недостатки:**\n",
    "    * **Latency & Compute:** Обработка трансформером на каждом из 16k запросов в секунду требует огромного кластера GPU. Уложиться в 435 мс можно, но это будет очень дорого.\n",
    "    * Сложнее интерпретировать, чем деревья.\n",
    "\n",
    "### Вариант 2: Градиентный бустинг (CatBoost / XGBoost)\n",
    "Классическое решение для индустрии. На вход подаются поведенческие фичи, графовые метрики (предварительно посчитанные) и текстовые эмбеддинги (как готовые векторы).\n",
    "\n",
    "* **Преимущества:**\n",
    "    * **Скорость:** Inference time измеряется миллисекундами даже на CPU. Легко держит 16k RPS.\n",
    "    * **Работа с табличными данными:** Лучше всех работает с категориальными признаками (ID товара, категории) и счетчиками поведения.\n",
    "    * **Интерпретируемость:** Легко получить Feature Importance (понять, почему отзыв забанен).\n",
    "* **Недостатки:**\n",
    "    * Сам по себе не \"читает\" текст. Требует отдельного этапа генерации эмбеддингов (через быстрый NLP-сервис).\n",
    "\n",
    "### Вариант 3: Graph Neural Network (GNN - например, GraphSAGE)\n",
    "Модель, обучаемая непосредственно на графе взаимодействий User-Item.\n",
    "\n",
    "* **Преимущества:**\n",
    "    * Идеально для обнаружения \"колец ботов\" и сложных схем накрутки, которые не видны на уровне одного отзыва.\n",
    "* **Недостатки:**\n",
    "    * Сложность внедрения в Real-time (inductive learning). Сбор соседей (neighbor sampling) при инференсе может создавать большую задержку.\n",
    "\n",
    "---\n",
    "\n",
    "### Финальный выбор для проектирования\n",
    "\n",
    "Я выбираю **Вариант 2: Градиентный бустинг (CatBoost)**, усиленный признаками из других моделей.\n",
    "\n",
    "**Обоснование выбора:**\n",
    "1.  **Нагрузка (16,370 RPS):** Это очень высокий RPS. Чистый BERT или GNN в реал-тайме потребуют неоправданно дорогой инфраструктуры. CatBoost эффективен и быстр.\n",
    "2.  **Природа данных:** Фейковые отзывы часто выдают себя не текстом (текст может быть идеальным), а метаданными (IP, тайминги, отсутствие покупки). Бустинг здесь король.\n",
    "3.  **Гибридный подход (Stacking):**\n",
    "    * *Текст:* Мы будем использовать легковесную NLP-модель (например, FastText или дистиллированный BERT в виде микросервиса) для получения вектора текста, который пойдет как *feature* в CatBoost.\n",
    "    * *Графы:* Мы будем использовать GNN в оффлайн-режиме (batch) для расчета `risk_score` пользователя на основе его связей, и передавать этот скор в CatBoost как фичу.\n",
    "\n",
    "**Итоговая модель:** CatBoost Classifier.\n",
    "**Входные данные:** User features + Behavioral counters + Text Embeddings (pre-calculated) + Graph Scores (pre-calculated)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583de9f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Часть 2: Проектирование архитектуры\n",
    "\n",
    "## 1\\. Высокоуровневая архитектура (High-Level Design)\n",
    "\n",
    "Система строится по принципу микросервисов. Основной поток блокировки фейков работает в реальном времени (Synchronous Flow), чтобы предотвратить публикацию спама. Тяжелые вычисления (обновление графов, глубокий анализ) вынесены в асинхронный контур.\n",
    "\n",
    "### Основные компоненты:\n",
    "\n",
    "  * **Review Service:** Бэкенд, принимающий отзывы от пользователей.\n",
    "  * **Anti-Fake Gateway (ML Service):** Единая точка входа для проверки контента.\n",
    "  * **Feature Store:** Центральное хранилище признаков (разделенное на Online и Offline).\n",
    "  * **Message Queue (Kafka):** Шина данных для асинхронной обработки.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    Client[Пользователь / Frontend] -->|1. POST /review| LB[Load Balancer]\n",
    "    LB -->|2. Route Request| ReviewSvc[Review Service]\n",
    "    \n",
    "    subgraph \"ML Subsystem (Sync Path)\"\n",
    "        ReviewSvc -->|3. Check Fraud gRPC| MLService[Anti-Fake ML Service]\n",
    "        MLService -->|4. Get Features| OnlineFS[(Redis: Online Feature Store)]\n",
    "        MLService -->|5. Predict| Model[CatBoost Model]\n",
    "        Model -->|6. Score & Decision| ReviewSvc\n",
    "    end\n",
    "    \n",
    "    subgraph \"Async Processing (Background)\"\n",
    "        ReviewSvc -.->|7. Event: ReviewCreated| Kafka[Kafka]\n",
    "        Kafka --> Processor[Stream Processor / Flink]\n",
    "        Processor -->|Update Counters| OnlineFS\n",
    "        Processor -->|Save to Lake| DataLake[(Data Lake / S3)]\n",
    "    end\n",
    "\n",
    "    ReviewSvc -->|8. Save if approved| DB[(Primary DB)]\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## 2\\. Архитектура Data Pipeline\n",
    "\n",
    "Для обеспечения низкой задержки и актуальности данных используется **Lambda-архитектура** (или Kappa), разделяющая потоковую и пакетную обработку.\n",
    "\n",
    "**Ключевая проблема:** Как подать в модель информацию о том, что пользователь оставил 50 отзывов за последние 10 минут?\n",
    "**Решение:** Stream Processing (Flink/Spark Streaming).\n",
    "\n",
    "### Поток данных:\n",
    "\n",
    "1.  **Batch Layer (Холодные данные):** Исторические логи, графовые связи, разметка модераторов. Используется для обучения модели.\n",
    "2.  **Speed Layer (Горячие данные):** События в реальном времени (клики, новые отзывы). Используется для подсчета счетчиков (Velocity features) и записи их в Redis.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph \"Sources\"\n",
    "        Logs[App Logs]\n",
    "        DB[User DB]\n",
    "        Events[User Events]\n",
    "    end\n",
    "\n",
    "    subgraph \"Ingestion\"\n",
    "        Kafka[Apache Kafka]\n",
    "    end\n",
    "\n",
    "    subgraph \"Processing Layers\"\n",
    "        SparkBatch[Spark Batch ETL]\n",
    "        FlinkStream[Flink Stream Proc]\n",
    "    end\n",
    "\n",
    "    subgraph \"Storage & Feature Store\"\n",
    "        DWH[(DWH / ClickHouse)]\n",
    "        Redis[(Redis: Online Features)]\n",
    "        S3[(Data Lake: S3)]\n",
    "    end\n",
    "\n",
    "    Logs & Events --> Kafka\n",
    "    DB --> SparkBatch\n",
    "    \n",
    "    %% Speed Path\n",
    "    Kafka --> FlinkStream\n",
    "    FlinkStream -- \"Real-time Aggregates (Velocity)\" --> Redis\n",
    "    \n",
    "    %% Batch Path\n",
    "    Kafka --> S3\n",
    "    S3 --> SparkBatch\n",
    "    SparkBatch -- \"Graph Scores / User Embeddings\" --> Redis\n",
    "    SparkBatch --> DWH\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## 3\\. Архитектура Training Pipeline\n",
    "\n",
    "Обучение происходит оффлайн по расписанию (например, раз в неделю) или при деградации метрик.\n",
    "\n",
    "**Особенности:**\n",
    "\n",
    "  * Использование **Feature Store** как единственного источника правды (чтобы фичи на трейне совпадали с фичами на инференсе).\n",
    "  * **Graph Pre-processing:** Перед обучением CatBoost запускается алгоритм (например, Louvain community detection) для расчета графовых скоров.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```mermaid\n",
    "stateDiagram-v2\n",
    "    direction LR\n",
    "    \n",
    "    state \"Data Lake / DWH\" as Data\n",
    "    state \"Feature Store (Offline)\" as FS\n",
    "    \n",
    "    state \"Training Pipeline (Airflow/Kubeflow)\" as Pipe {\n",
    "        Preproc: Data Preprocessing\n",
    "        Split: Train/Test Split\n",
    "        Graph: Graph Feature Calc (NetworkX/SparkGraph)\n",
    "        Train: Train CatBoost\n",
    "        Eval: Evaluation (AUC/Precision)\n",
    "    }\n",
    "    \n",
    "    state \"Model Registry (MLflow)\" as Registry\n",
    "    \n",
    "    Data --> FS: Sync\n",
    "    FS --> Preproc: Fetch Training Dataset\n",
    "    Preproc --> Graph\n",
    "    Graph --> Split\n",
    "    Split --> Train\n",
    "    Train --> Eval\n",
    "    Eval --> Registry: Register if Metric > Threshold\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## 4\\. Архитектура Inference Pipeline (Serving)\n",
    "\n",
    "Самая критичная часть. Нам нужно уложиться в **435 мс** при **16k RPS**.\n",
    "\n",
    "**Стратегия оптимизации задержки:**\n",
    "\n",
    "1.  **Предвычисления (Pre-computation):** Графовые скоры и сложные поведенческие метрики уже лежат в Redis. Мы их просто читаем ($< 5$ мс).\n",
    "2.  **Текст:** Легковесная токенизация и инференс текстовой модели (например, дистиллированный BERT через ONNX Runtime или FastText).\n",
    "3.  **Модель:** CatBoost очень быстр на CPU.\n",
    "4.  **Скейлинг:** Kubernetes HPA (Horizontal Pod Autoscaler) добавляет поды при росте CPU/RPS.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant U as User\n",
    "    participant GW as API Gateway\n",
    "    participant ML as ML Service (K8s Pod)\n",
    "    participant R as Redis (Feature Store)\n",
    "    participant NLP as NLP Module (ONNX)\n",
    "    participant CB as CatBoost Predictor\n",
    "\n",
    "    U->>GW: POST /review (Text, UserID, ItemID)\n",
    "    activate GW\n",
    "    GW->>ML: PredictReq(Text, UserID)\n",
    "    activate ML\n",
    "    \n",
    "    par Parallel Fetching\n",
    "        ML->>R: MGET [User_Velocity, Graph_Risk_Score, Account_Age]\n",
    "        R-->>ML: Returns Vector [0.5, 0.9, 365] (2-5ms)\n",
    "    and NLP Embedding\n",
    "        ML->>NLP: GenerateEmbedding(Text)\n",
    "        NLP-->>ML: Returns Vector [0.1, ..., 0.05] (30-50ms)\n",
    "    end\n",
    "    \n",
    "    ML->>ML: Concat Features (User + Graph + Text)\n",
    "    \n",
    "    ML->>CB: Predict_Proba(Features)\n",
    "    CB-->>ML: Probability: 0.95 (Fake) (<10ms)\n",
    "    \n",
    "    ML-->>GW: Response: {is_fake: true, score: 0.95}\n",
    "    deactivate ML\n",
    "    \n",
    "    GW->>GW: Block Review\n",
    "    GW-->>U: Error: \"Review under moderation\"\n",
    "    deactivate GW\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### Комментарий к схемам для отчета:\n",
    "\n",
    "При реализации этой архитектуры достигается баланс между сложностью и скоростью:\n",
    "\n",
    "1.  **Online Feature Store (Redis):** Обеспечивает мгновенный доступ к \"медленным\" данным (графовые связи), которые были посчитаны заранее. Это разгружает Real-time пайплайн.\n",
    "2.  **Асинхронность:** Мы не пересчитываем граф при каждом запросе.\n",
    "3.  **ONNX/TensorRT:** Использование оптимизированных ранфтаймов для текстовой части критически важно для соблюдения SLA 435 мс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726c2b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Часть 3: Расчёты и нефункциональные требования\n",
    "\n",
    "## 1. Расчёт требований к пропускной способности (Throughput)\n",
    "\n",
    "### 1.1. Расчёт требуемого количества серверов (Inference Service)\n",
    "\n",
    "**Дано:**\n",
    "* Пиковая нагрузка: $RPS_{peak} = 16,370$ запросов в секунду.\n",
    "* Допустимая задержка (SLA): $L = 435$ мс.\n",
    "* Целевая утилизация CPU: $U_{target} = 70\\%$ (оставляем запас для всплесков).\n",
    "* Предполагаемая производительность одного ядра: $RPS_{core} \\approx 200 - 300$ (для CatBoost + Redis Lookups + легкий NLP). Возьмем консервативное значение: $RPS_{core} = 250$.\n",
    "\n",
    "**Расчёт общего требуемого количества ядер:**\n",
    "$$Cores_{required} = \\frac{RPS_{peak}}{RPS_{core} \\times U_{target}}$$\n",
    "$$Cores_{required} = \\frac{16,370}{250 \\times 0.70} \\approx \\frac{16,370}{175} \\approx 93.5 \\text{ ядер}$$\n",
    "\n",
    "**Вывод:** Для обслуживания пиковой нагрузки нам потребуется минимальный кластер, эквивалентный **94 ядрам CPU** (предполагая высокопроизводительные инстансы, например, 8-ядерные).\n",
    "\n",
    "* Если использовать **8-ядерные** инстансы: $\\lceil 94 / 8 \\rceil = 12$ серверов.\n",
    "* Если использовать **16-ядерные** инстансы: $\\lceil 94 / 16 \\rceil = 6$ серверов.\n",
    "\n",
    "**Рекомендация:** Развернуть **7-8 инстансов** (для запаса и отказоустойчивости) CatBoost ML Service с 16 ядрами каждый, используя Kubernetes HPA для автоматического масштабирования.\n",
    "\n",
    "### 1.2. Расчёт задержки (Latency Budget)\n",
    "\n",
    "Проверим, как распределяется SLA в 435 мс по архитектуре:\n",
    "\n",
    "| Этап | Компонент | Примерная задержка | Обоснование |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **1.** Сеть / LB | Load Balancer / API Gateway | 10 мс | Сетевые накладные расходы |\n",
    "| **2.** Сбор признаков | Online Feature Store (Redis) | 5 - 10 мс | Одно чтение/запись по ключу |\n",
    "| **3.** Текстовые признаки | NLP Service (ONNX/FastText) | 30 - 60 мс | Легковесный инференс (самый долгий этап) |\n",
    "| **4.** Инференс модели | CatBoost Predictor | 5 - 15 мс | Быстрый алгоритм, инференс на CPU |\n",
    "| **5.** Логирование/Ответ | Review Service/DB | 10 мс | Запись в лог, возврат ответа |\n",
    "| **Итоговый P99** | **Сумма** | **~ 60 - 105 мс** | **Далеко ниже SLA (435 мс)** |\n",
    "\n",
    "**Вывод:** Система CatBoost с предварительно рассчитанными признаками и выделенным NLP-модулем легко укладывается в требуемые **435 мс** даже при P99.\n",
    "\n",
    "## 2. Расчёт требований к хранилищу (Feature Store)\n",
    "\n",
    "**Цель:** Оценить размер Online Feature Store (Redis) для хранения оперативных признаков.\n",
    "\n",
    "**Дано:**\n",
    "* DAU: $3,598,581$ активных пользователей.\n",
    "* Количество товаров: Пусть будет $1,000,000$ (типично для крупного e-commerce).\n",
    "* Срок хранения поведенческих данных: 30 дней.\n",
    "\n",
    "**Признаки для хранения (Feature Vectors):**\n",
    "\n",
    "1.  **Признаки пользователя (User Features):**\n",
    "    * Признаки: Возраст аккаунта, средний рейтинг, риск-скор (из GNN), счетчики активности за 1ч/1д/7д (всего $\\approx 50$ признаков).\n",
    "    * Размер одного вектора: $50 \\times 4$ байта (Float) $\\approx 200$ байт.\n",
    "    * Общий объём для пользователей: $3.6M \\text{ пользователей} \\times 200 \\text{ байт} \\approx 720 \\text{ МБ}$.\n",
    "\n",
    "2.  **Эмбеддинги товаров (Item Embeddings):**\n",
    "    * Эмбеддинг: 128-мерный вектор.\n",
    "    * Размер: $128 \\times 4$ байта (Float) $\\approx 512$ байт.\n",
    "    * Общий объём для товаров: $1M \\text{ товаров} \\times 512 \\text{ байт} \\approx 512 \\text{ МБ}$.\n",
    "\n",
    "3.  **Горячие счетчики (Hot/Time-series Features):**\n",
    "    * Хранение тайм-серии для каждого пользователя (например, последние 10 действий).\n",
    "    * Объём: $\\approx 500 \\text{ МБ}$.\n",
    "\n",
    "**Итоговый объём Online Feature Store (Redis):**\n",
    "$$V_{total} \\approx 720 \\text{ МБ} + 512 \\text{ МБ} + 500 \\text{ МБ} \\approx 1.73 \\text{ ГБ}$$\n",
    "\n",
    "**Вывод:** Требования к хранилищу для горячих данных крайне низкие (менее **2 ГБ**). Это подтверждает, что **Redis Cluster** (или эквивалент) отлично подходит для **Online Feature Store** с минимальными операционными расходами.\n",
    "\n",
    "## 3. Масштабируемость и надёжность (Scalability and Reliability)\n",
    "\n",
    "### Масштабируемость (Scalability)\n",
    "* **Горизонтальное масштабирование (Horizontal Scaling):**\n",
    "    * **ML Service:** Легко масштабируется через Kubernetes (K8s) и HPA (Horizontal Pod Autoscaler), так как инстансы без состояния (stateless). При росте RPS K8s автоматически добавит инстансы, чтобы утилизация CPU не превысила 70%.\n",
    "    * **Kafka:** Обеспечивает масштабируемость Data Pipeline, позволяя обрабатывать растущий объем событий без потери данных.\n",
    "* **Модульность:** Архитектура на микросервисах позволяет независимо масштабировать самый медленный компонент (NLP Module) и самый нагруженный (CatBoost Service).\n",
    "\n",
    "### Надёжность (Reliability)\n",
    "* **Отказоустойчивость (Fault Tolerance):**\n",
    "    * Все ключевые компоненты (Kafka, Redis, K8s, DB) развертываются в **кластерной конфигурации** с репликацией между минимум **тремя зонами доступности (AZs)**.\n",
    "    * **Model Rollback:** Использование **Model Registry (MLflow)** позволяет мгновенно откатить модель до предыдущей версии, если новая модель вызывает деградацию метрик или ошибки.\n",
    "* **Мониторинг:**\n",
    "    * Настройка сквозного мониторинга задержки (Latency P99) и бизнес-метрик (False Positive Rate, False Negative Rate) в реальном времени.\n",
    "    * Автоматические алерты при превышении 400 мс задержки или 80% утилизации CPU.\n",
    "\n",
    "## Заключение по НФТ\n",
    "\n",
    "Система, основанная на гибридной архитектуре CatBoost + Feature Store, демонстрирует высокую производительность и масштабируемость. Она **с запасом укладывается** в требуемую задержку (**435 мс**) и способна обрабатывать пиковую нагрузку в **16,370 RPS** за счет эффективного использования CPU и предварительного вычисления сложных признаков (графов) в оффлайн-режиме."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
